{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DNSDig","text":"<p>A weekend project that turns into something semi serious to learn about DNS in Python while investigating what it's like to build an API in 2023 with FastAPI, Pydantic and DNSPython. Authentication and authorization is handled by Kinde.</p>"},{"location":"#why-build-this","title":"Why Build This?","text":"<p>More about it in this blog post.</p>"},{"location":"dnsdig-api/","title":"DNSDig API","text":"<p>As mentioned before, DNSDig API is built on top of FastAPI, Pydantic and DNSPython. Authentication and authorization is handled by Kinde. MongoDB is the choice for the database and Redis is used for rate limiting so far.</p> <p>This started as a hack and challenge to finish in 24 hours but I can say that it's still a work in progress. The API is deployed at https://dnsdig-api.bango29.com and the endpoint docs are available at https://dnsdig-api.bango29.com/docs. The API is free to use but rate limited as described further down in this page. </p> <p>Register for an account and create an application if you want to use the API without rate limits.</p>"},{"location":"dnsdig-api/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<p>Kinde is responsible to issue access tokens, refresh tokens and revoke tokens. DNSDig API will only accept access tokens issued by Kinde. The access token is passed in the <code>Authorization</code> header with the <code>Bearer</code> scheme. The access tokens are issued as JWT tokens.</p>"},{"location":"dnsdig-api/#user-flow","title":"User Flow","text":"<p>DNSDig API uses OAuth 2.0 to authenticate users indirectly by using Kinde. The followings are sequence diagrams of how the authentication flow works. The intended audience for this flow are humans using a web browser.</p>"},{"location":"dnsdig-api/#loginregister-flow","title":"Login/Register Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    User -&gt; \"Web Frontend\": Clicks the login or register button\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/me/login-url\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with a login URL\n    \"Web Frontend\" -&gt;&gt; User: Redirects to the login URL\n    User -&gt;&gt; Kinde: Logs in or registers\n    Kinde -&gt;&gt; \"Web Frontend\": [GET] /callbacks/kinde\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/callbacks/kinde\n    \"DNSDig API\" -&gt;&gt; Kinde: Exchange the code for an access token\n    Kinde -&gt;&gt; \"DNSDig API\": Respond with the access token\n    \"DNSDig API\" -&gt;&gt; \"DNSDig API\": Maybe register a new user\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with the access token and refresh token\n    \"Web Frontend\" -&gt;&gt; User: Redirects to homepage</code></pre>"},{"location":"dnsdig-api/#refresh-token-flow","title":"Refresh Token Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    User -&gt;&gt; \"Web Frontend\": Resolve a hostname\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/resolve/google.com\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with a 401 - Access Token is expired\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/oauth2/token\n    \"DNSDig API\" -&gt;&gt; Kinde: Exchange refresh token for an access token\n    Kinde -&gt;&gt; \"DNSDig API\": Respond with an access token\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with the access token and refresh token\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/resolve/google.com\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with the resolved records\n    \"Web Frontend\" -&gt;&gt; User: Renders the resolved records page</code></pre>"},{"location":"dnsdig-api/#machine-to-machine-flow","title":"Machine to Machine Flow","text":"<p>Before being able to make requests to the API, a Machine to Machine (M2M) application needs to register their application first through DNSDig API's web frontend. This flow as the name implies is intended for machine to machine communication. It's not recommended to use this flow for mobile apps.</p> <p>This part of the API does not use Kinde for authentication and authorization. Instead it's a custom access token and refresh token issuance that looks like an OAuth 2.0 flow. The access token is not a JWT token, it's a random string prefixed with <code>m2m</code>.</p>"},{"location":"dnsdig-api/#register-application-flow","title":"Register Application Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    Developer -&gt;&gt; \"Web Frontend\": Registers a new application\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [POST] /v1/me/applications\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with client credentials\n    \"Web Frontend\" -&gt;&gt; Developer: Render application detail page</code></pre>"},{"location":"dnsdig-api/#get-my-applications-flow","title":"Get My Applications Flow","text":"<pre><code>sequenceDiagram\n    autonumber\n    Developer -&gt;&gt; \"Web Frontend\": Clicks on \"My Applications\"\n    \"Web Frontend\" -&gt;&gt; \"DNSDig API\": [GET] /v1/me/applications\n    \"DNSDig API\" -&gt;&gt; \"Web Frontend\": Responds with this developer's applications\n    \"Web Frontend\" -&gt;&gt; Developer: Render application list page</code></pre>"},{"location":"dnsdig-api/#obtain-access-token","title":"Obtain Access Token","text":"<pre><code>sequenceDiagram\n    autonumber\n\n    Machine -&gt;&gt; \"DNSDig API\": [POST] /v1/oauth2/token\n    note right of Machine: Client ID and Client Secret in the request body with a grant type of client credentials\n    \"DNSDig API\" -&gt;&gt; MongoDB: Save new access token and refresh token pair\n    MongoDB -&gt;&gt; \"DNSDig API\": Respond with success\n    \"DNSDig API\" -&gt;&gt; Machine: Responds with the access token and refresh token</code></pre>"},{"location":"dnsdig-api/#refresh-token","title":"Refresh Token","text":"<pre><code>sequenceDiagram\n    autonumber\n\n    Machine -&gt;&gt; \"DNSDig API\": [POST] /v1/oauth2/token\n    note right of Machine: Refresh token included in the request body with a grant type of refresh token\n    \"DNSDig API\" -&gt;&gt; MongoDB: Save new access token and refresh token pair\n    MongoDB -&gt;&gt; \"DNSDig API\": Respond with success\n    \"DNSDig API\" -&gt;&gt; Machine: Responds with the access token and refresh token</code></pre>"},{"location":"dnsdig-api/#rate-limits","title":"Rate Limits","text":"<p>In DNSDig, access tokens are used for certain endpoints to avoid rate limiting. Requests that are authorized with access tokens will have an unlimited rate limit from the API's perspective than requests that are not authorized with access tokens. Rate limiting authorized requests is delegated to a reverse proxy like nginx or Traefik. DNSDig's publicly reachable API is deployed behind Cloudflare, therefore Cloudflare's policy applies.</p>"},{"location":"dnsdig-api/#rate-limited-endpoints","title":"Rate Limited Endpoints","text":"<p>The endpoints' rate limit is configurable via these environment variables:</p> Name Description <code>THROTTLER_TIMES</code> Required string <code>THROTTLER_SECONDS</code> Required string <p><code>THROTTLER_SECONDS</code> determines the number of seconds elapsed before the rate limit is reset. <code>THROTTLER_TIMES</code> determines the number of requests allowed to be made within <code>THROTTLER_SECONDS</code> seconds.</p>"},{"location":"dnsdig-api/#implementation","title":"Implementation","text":"<p>Rate limiting is implemented by using the fastapi-limiter library. In practice Redis is required to maintain the state of the rate limit. The Redis connection is configured via the <code>REDIS_URL</code> environment variable. Below is taken from a public endpoint protected with the rate limiter. The <code>settings</code> variable is a Pydantic <code>BaseSettings</code> class that is used to read environment variables and or <code>.env</code> files.</p> <pre><code>@router.get(\n    \"/freesolve/{name}\",\n    summary=\"Resolve multiple DNS records - Throttled\",\n    tags=[\"Resolver\", \"Throttled\"],\n    response_model=Dict[RecordTypes, ResolverResult],\n    dependencies=[Depends(RateLimiter(times=settings.throttler_times, seconds=settings.throttler_seconds))],\n)\nasync def freesolve_dns_records(name: str, mongo_client: MongoClient = Depends(MongoClientDependency())):\n    async with mongo_client.transaction():\n        async with Context.public():\n            # ...\n</code></pre>"},{"location":"dnsdig-api/#raise-exceptions-anywhere","title":"Raise Exceptions Anywhere","text":"<p>In the example endpoint written above, the mechanics of the endpoint is wrapped with an async context manager to ensure MongoDB's transactions are in effect. Therefore, whenever an exception is raised anywhere in the codebase (even by 3rd party codes in libraries), the transaction will then be rolled back, no changes are saved to MongoDB. This is particularly useful to avoid half measured database operations.</p> <pre><code>    # ...\n    @asynccontextmanager\n    async def transaction(self) -&gt; motor_asyncio.AsyncIOMotorClientSession:\n        async with await self.client.start_session() as session:\n            async with session.start_transaction():\n                try:\n                    yield session\n                except Exception as exc:\n                    await session.abort_transaction()\n                    raise exc\n    # ...\n\n# Taken from dnsdig/libshared/models.py\n</code></pre> <p>Anywhere in the codebase, it's encouraged to raise exceptions instead of returning error responses. The exception will be caught by the exception handler and then the error response will be returned to the client. Managed exceptions are raised using FastAPI's standard exception object <code>HTTPException</code>.</p> <pre><code>    # ...\n    async def _authorize_m2m_token(self):\n        query = {\"token\": self.access_token}\n        token = await monq_find_one(model=Token, query=query, project_to=Token)\n        if not token:\n            raise HTTPException(status_code=401, detail=\"Invalid token\")\n        if token.token_type != TokenTypes.M2M:\n            raise HTTPException(status_code=401, detail=\"Invalid token\")\n        if token.expires_at &lt; datetime.utcnow():\n            raise HTTPException(status_code=401, detail=\"Token expired\")\n\n        self.current_user = await User.get_user_by_app_client_id(client_id=token.owner_id)\n        if self.current_user.is_blocked:\n            raise HTTPException(\n                status_code=403, detail=\"The owner of the application is blocked from using this service\"\n            )\n    # ...\n\n# Taken from dnsdig/libshared/context.py\n</code></pre>"},{"location":"dnsdig-api/#ipv6-support","title":"IPv6 Support","text":"<p>DNSDig API is built on top of dnspython in which IPv6 resolvers are supported. However, depending on your own network setup, DNSDig API might not be able to resolve records using IPv6 resolvers. For this reason, IPv6 endpoints are dedicated and ends with a <code>6</code> prefix. If your network supports IPv6 and a request is made to one of the IPv6 endpoints, the API will use IPv6 resolvers to resolve the records.</p> <p>On the contrary, <code>AAAA</code> records can be resolved regardless if you use the IPv6 endpoints or the regular endpoints.</p> <p>DNSDig API also have tests for IPv6 resolvers but as of now commented from the source code. This is because Github's workflow runners does not support IPv6. If this changes then the tests will be uncommented.</p>"},{"location":"dnsdig-api/#ip-geolocation","title":"IP Geolocation","text":"<p>DNSDig API uses ipinfo.io to geolocate IP addresses. The API is rate limited to 50,000 requests per month. The API is free to use but you need to register for an account to get an API key. When this quota is used up, DNSDig API will not include geolocation data in the response.</p>"},{"location":"dnsdigd/","title":"DNSDigd","text":"<p>After completing the API, I was thinking more about having my own DNS daemon that would serve my home network. Where I live, we only have 2 ISPs nationwide, competition is not really a thing. So I wanted to learn more why my DNS requests are resolving quite slow. </p> <p>I have a fiber connection terminating at the ONT at home which is then fed to a pfsense box. I always thought my pfsense box is limited in computing power but when I see the state table, it's not even reaching 1% of usage.</p> <p>While I'm at it, I want to log query times so I can have a sense of what's going on with the requests. DNS query responses are also cached to a Redis instance with their corresponding TTL.</p>"},{"location":"dnsdigd/#resolvers","title":"Resolvers","text":"<p>As stated in the API docs, I'm using dnspython to do the heavy lifting for DNS requests and responses. I haven't had enough time spent with it to have a stronger opinion but I have no complaints, so far whatever my needs are it's been able to fulfill them.</p> <p>Out of the box, dnspython supports many kinds of resolvers. At first I stuck with DNS over HTTPS for about 2 weeks. However, HTTPS connections are by design uses TCP as the protocol. I have an assumption in my head that packets are getting lost in the wild, I saw query times up to 9 seconds which is unacceptable by any standard.</p> <p>The slower your DNS responses are, the slower you feel browsing the interwebs. No it's not a placebo, there are plenty of loaders to convince you otherwise.</p> <p>The MongoDB query to generate analytics numbers is below, all numbers are in milliseconds.</p> <pre><code>db.getCollection(\"analytics\").aggregate([\n    {\n        \"$match\": {\n            \"created_at\": {\n                \"$gte\": ISODate(\"2023-10-18T12:00:00Z\"), \n                \"$lte\": ISODate(\"2023-10-28T12:00:00Z\")\n            }\n        }\n    },\n    {\n        \"$group\": {\n            \"_id\": null,\n            \"average\": {\"$avg\": \"$resolve_time\"},\n            \"median\": {\"$median\": {\"input\": \"$resolve_time\", \"method\": \"approximate\"}},\n            \"minimum\": {\"$min\": \"$resolve_time\"},\n            \"maximum\": {\"$max\": \"$resolve_time\"},\n            \"percentiles\": {\n                \"$percentile\": {\"input\": \"$resolve_time\", \"p\": [0.75, 0.99], \"method\": \"approximate\"}\n            },\n        }\n    },\n    {\"$project\": {\"_id\": false}},\n])\n</code></pre>"},{"location":"dnsdigd/#dns-over-https","title":"DNS over HTTPS","text":"<p>I'm using Google's DoH as the resolver. The Google brand should give some peace of mind. Here are the analytics results:</p> <pre><code>{\n    \"average\" : 79.42515112305975,\n    \"median\" : 41.88292455772905,\n    \"minimum\" : 0.27441978454589844,\n    \"maximum\" : 9163.366079330444,\n    \"percentiles\" : [\n        138.79384915674967,\n        365.0222927369246\n    ]\n}\n</code></pre> <p>The average and median numbers are very good, this tells me at least 50% of the time, DNS requests are served below the average response time. The 75th and 99th percentiles are indicative of uncached DNS requests, which in my opinion is still acceptable. The outlier is the maximum number, 9 seconds is unacceptable.</p>"},{"location":"dnsdigd/#dns-over-tls","title":"DNS over TLS","text":"<p>For this, I use a mix of Google's DoT and Cloudflare's DoT. The results are promising:</p> <pre><code>{\n    \"average\" : 51.470825286843464,\n    \"median\" : 2.6083139806529716,\n    \"minimum\" : 0.5116462707519531,\n    \"maximum\" : 2769.749164581299,\n    \"percentiles\" : [\n        23.65206792398557,\n        470.14613223798347\n    ]\n}\n</code></pre> <p>I was right. TCP packets got lost in the wild. The maximum number is still high but it's much better than the DoH counterpart. The average and median numbers are also better, this tells me that the majority of DNS requests are served below the average response time. Another conclusion I can take is that uncached DNS responses are much much faster.</p> <p>With these results, I can be sure loaders are caused by the website's performance rather than my DNS performance.</p>"},{"location":"dnsdigd/#how-it-works","title":"How It Works","text":"<pre><code>sequenceDiagram\n    autonumber\n    Client -&gt;&gt; DNSDigd: DNS Request over Port 53\n    alt Adblocker Enabled\n        DNSDigd -&gt;&gt; Redis: Check if record exists\n        Redis -&gt;&gt; DNSDigd: Record exists\n        DNSDigd -&gt;&gt; Client: Return blackholed response\n    else Adblocker Disabled\n        DNSDigd -&gt;&gt; Redis: Check if record exists\n        alt Cache Hit\n            Redis -&gt;&gt; DNSDigd: Record exists\n            DNSDigd -&gt;&gt; Client: Return cached DNS Response\n        else Cache Miss\n            Redis -&gt;&gt; DNSDigd: Record does not exist\n            DNSDigd -&gt;&gt; \"DoT Resolver\": Forward DNS Request\n            \"DoT Resolver\" -&gt;&gt; DNSDigd: Return DNS Response\n            DNSDigd -&gt;&gt; Redis: Cache DNS Response\n        end\n    end\n    DNSDigd -&gt;&gt; Client: Return DNS Response\n    opt Analytics\n        DNSDigd -&gt;&gt; MongoDB: Log DNS Request\n        MongoDB -&gt;&gt; DNSDigd: Respond with success\n    end</code></pre>"},{"location":"dnsdigd/#caveats","title":"Caveats","text":"<p>This setup is effective with a few notes to keep in mind:</p> <ul> <li>Docker doesn't like DNS daemons running on port 53, I'm running DNSDigd in a VM</li> <li>DNSDigd is not a recursive resolver, it only forwards requests to DoT resolvers</li> </ul>"},{"location":"dnsdigd/#adblocker","title":"Adblocker","text":"<p>The adblocker database is sourced from https://github.com/anudeepND/blacklist. Reading into the contents of the hosts file, records are resolved to <code>0.0.0.0</code>. This breaks the websites I visit, they keep loading forever. Fortunately the adblocker is controlled by an environment variable to switch on/off.</p> <p>To import the adblocker hosts, I wrote a small Python script that reads the hosts file and inserts them into Redis. Run this once.</p> <pre><code>$ python dnsdig/appclis/dns-blacklist-importer.py \\\n  --redis-url redis://localhost:6379\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Python 3.11 is required to run this project. If you don't have it installed, you can use pyenv.</p>"},{"location":"getting-started/#poetry","title":"Poetry","text":"<p>Dependencies are managed by Poetry. Install Poetry and then install the dependencies.</p> <pre><code>$ curl -sSL https://install.python-poetry.org | python3.11 -\n</code></pre>"},{"location":"getting-started/#dnsdig-api","title":"DNSDig API","text":"<p>Now let's get the API up and running.</p> <pre><code>$ git clone git@github.com:tistaharahap/dnsdig.git\n$ cd dnsdig\n$ poetry install\n</code></pre>"},{"location":"getting-started/#kinde","title":"Kinde","text":"<p>Go to Kinde and create an account. Then create a new project and add a new API. You'll need the Client ID, Client Secret and Kinde's host for your project to run. Included with this repo is an example <code>.env</code> file.</p> <p>In Kinde, add <code>http://localhost:8080/v1/callbacks/kinde</code> as a callback URL for your API.</p>"},{"location":"getting-started/#env-file","title":".env File","text":"<p>Edit the <code>.env.example</code> file to include your Kinde credentials and rename it to <code>.env</code>.</p> <pre><code>$ vim .env.example\n$ cp .env.example .env\n</code></pre> <p>The API will not run if any of the required environment variables are missing, make sure you have them all.</p>"},{"location":"getting-started/#running-the-api","title":"Running The API","text":"<p>When everything is set, run the API.</p> <pre><code>$ chmod +x run.sh\n$ ./run.sh\n</code></pre> <p>The API will be available at <code>http://localhost:8080</code> and the docs will be available at <code>http://localhost:8080/docs</code>.</p>"},{"location":"getting-started/#protected-endpoints","title":"Protected Endpoints","text":"<p>Before you can make requests to the protected endpoints, you'll need to create a user. Assuming that the API is running, use the API docs and go to the link below:</p> <p>http://localhost:8080/docs#/Me/get_login_url_v1_me_login_url_post</p> <p>Click the <code>Try it out</code> button, use an empty body in <code>Request Body</code> by entering <code>{}</code> and then click the <code>Execute</code> button.</p> <p>Note: If you're building a web frontend on top of this API, you can choose to use your own <code>state</code> parameter and the API provides a <code>store</code> parameter that you can use to store any data you want to be returned to your app after the user has logged in. </p> <p>In the response, you will find a <code>loginUrl</code> key, copy and paste the value to your browser. You will be redirected to Kinde's login page. After you've logged in, you will be redirected back to the API and your access token will be given in the response.</p> <p>You can then use the access token to authorize yourself in the API docs. Click the <code>Authorize</code> button on the top right corner of the API docs and enter <code>&lt;access_token&gt;</code> in the <code>Value</code> field and click the <code>Authorize</code> button.</p>"},{"location":"getting-started/#running-with-docker","title":"Running With Docker","text":"<p>You can also run the API with Docker. Make sure you have Docker installed and then run the commands below.</p> <pre><code>$ docker build -t docker_username/docker_repo:latest .\n$ docker run -d --name dnsdig -p 8080:8080 \\\n  -e WEB_CONCURRENCY=$WEB_CONCURRENCY \\\n  -e ENV=$ENV \\\n  -e MONGO_URL=$MONGO_URL \\\n  -e AUTH_JWKS_URL=$AUTH_JWKS_URL \\\n  -e AUTH_JWT_ALGO=$AUTH_JWT_ALGO \\\n  -e AUTH_PROVIDER_HOST=$AUTH_PROVIDER_HOST \\\n  -e AUTH_PROVIDER_CLIENT_ID=$AUTH_PROVIDER_CLIENT_ID \\\n  -e AUTH_PROVIDER_CLIENT_SECRET=$AUTH_PROVIDER_CLIENT_SECRET \\\n  -e AUTH_PROVIDER_REDIRECT_URI=$AUTH_PROVIDER_REDIRECT_URI \\\n  -e REDIS_URL=$REDIS_URL \\\n  -e THROTTLER_TIMES=$THROTTLER_TIMES \\\n  -e THROTTLER_SECONDS=$THROTTLER_SECONDS \\\n  -e IPINFO_HOST=$IPINFO_HOST \\\n  -e IPINFO_TOKEN=$IPINFO_TOKEN \\\n  -e APP=$APP \\\n  -e PORT=$PORT \\\n  -e HOST=$HOST \\\n  docker_username/docker_repo:latest\n</code></pre> <p>Or if you want to get a prebuilt image, you can do the below.</p> <pre><code>$ docker run -d --name dnsdig -p 8080:8080 \\\n  -e WEB_CONCURRENCY=$WEB_CONCURRENCY \\\n  -e ENV=$ENV \\\n  -e MONGO_URL=$MONGO_URL \\\n  -e AUTH_JWKS_URL=$AUTH_JWKS_URL \\\n  -e AUTH_JWT_ALGO=$AUTH_JWT_ALGO \\\n  -e AUTH_PROVIDER_HOST=$AUTH_PROVIDER_HOST \\\n  -e AUTH_PROVIDER_CLIENT_ID=$AUTH_PROVIDER_CLIENT_ID \\\n  -e AUTH_PROVIDER_CLIENT_SECRET=$AUTH_PROVIDER_CLIENT_SECRET \\\n  -e AUTH_PROVIDER_REDIRECT_URI=$AUTH_PROVIDER_REDIRECT_URI \\\n  -e REDIS_URL=$REDIS_URL \\\n  -e THROTTLER_TIMES=$THROTTLER_TIMES \\\n  -e THROTTLER_SECONDS=$THROTTLER_SECONDS \\\n  -e IPINFO_HOST=$IPINFO_HOST \\\n  -e IPINFO_TOKEN=$IPINFO_TOKEN \\\n  -e APP=$APP \\\n  -e PORT=$PORT \\\n  -e HOST=$HOST \\\n  tistaharahap/dnsdig:latest\n</code></pre>"},{"location":"getting-started/#environment-variables","title":"Environment Variables","text":"Name Description <code>WEB_CONCURRENCY</code> Optional string, defaults to 1 on macOS <code>ENV</code> Required string <code>MONGO_URL</code> Required string <code>AUTH_JWKS_URL</code> Required string <code>AUTH_JWT_ALGO</code> Required string <code>AUTH_PROVIDER_HOST</code> Required string <code>AUTH_PROVIDER_CLIENT_ID</code> Required string <code>AUTH_PROVIDER_CLIENT_SECRET</code> Required string <code>AUTH_PROVIDER_REDIRECT_URI</code> Required string <code>REDIS_URL</code> Required string <code>THROTTLER_TIMES</code> Required string <code>THROTTLER_SECONDS</code> Required string <code>IPINFO_HOST</code> Required string <code>IPINFO_TOKEN</code> Required string <code>HOST</code> Required string <code>PORT</code> Required string <code>APP</code> Fill with <code>dnsdigapi</code>"},{"location":"getting-started/#dns-dig-daemon","title":"DNS Dig Daemon","text":"<p>Included with this repo is a small daemon that accepts UDP DNS requests, forwards them to Google's DoH (DNS over HTTPS) DNS server and then response back to the UDP client. The main goal is to have my own UDP DNS server for my network at home.</p>"},{"location":"getting-started/#what-does-it-do","title":"What does it do?","text":"<p>I wrote this for my own use case. The bandwidth where I live in Dubai is plentiful, both for a the Fiber Optics connection at home and the 5G connection on my phone. But latency can be better IMO, I wanted to learn what's causing it.</p> <p>I have a <code>pfsense</code> router at home, it protected the home network reliably but it was only rocking am Intel Atom CPU which I suppose is enough for a home network. I never saw the state table even get 1% saturated, I have no reason to believe the router is the cause for latency.</p> <p>My other suspicion is DNS resolution. The TTL for most domains nowadays are usually 300 seconds, which is short enough to cause a lot of DNS requests. The <code>pfsense</code> router also acts as a DNS resolver, not a forwarder, could this be the cause?</p> <p>It's a reasonable conjecture to think that this small router with passive cooling would be overwhelmed with DNS requests, not enough single core IPC performance I suspect, and not enough number of cores.</p> <p>So while in the DNS topic, I wanted to do more than just think, I wanted to prove it. Long story short I wrote a Python daemon that accepts standard DNS requests, forwards them to Google's DoH and replies back to the client.</p> <p>Record caching is done in redis with a TTL matching of the answer's TTL. After every reply to the client, the daemon logs the time it took to resolve the request into MongoDB. After running the daemon for a few days, here are the numbers in millisecond:</p> <p></p> <p>As you can see, the maximum time it took to resolve a record spiked to ~9 second at least once. The good news is that 99% of the time, the daemon was able to resolve a record in 332 ms on average. The most interesting is the minimum time which is less than 1 ms, Redis is mighty.</p> <p>Subjectively speaking, I can feel the difference in latency when browsing the web. I'm not sure if it's placebo or not but I'm happy with the results.</p> <p>As an added bonus, because the daemon is forwarding requests to Google's DoH, my DNS requests are secure, bad actors (ISP or otherwise) won't be able to fake any DNS responses.</p> <p>The route to <code>dns.google</code> is also optimized, it took 9 hops from my machine to reach Google.</p> <p>It only took 9 hops to reach https://t.co/S7AfE22PAA so I think there's another factor at play here. I'm inclined to assume that since it's a TCP connection, some packets got lost in the wild. pic.twitter.com/mx9fvTMsdr</p>\u2014 Batista Harahap (@tista) October 22, 2023 <p>I'm going to enjoy this for a while and see if I can find any other bottlenecks in my network.</p>"},{"location":"getting-started/#environment-variables_1","title":"Environment Variables","text":"Name Description <code>APP</code> Required string <code>DB_NAME</code> Required string <code>PORT</code> Required string <code>HOST</code> Required string <code>MONGO_URL</code> Required string <code>REDIS_URL</code> Required string <code>USE_ADBLOCKER</code> Optional boolean, defaults to false"},{"location":"getting-started/#getting-started_1","title":"Getting Started","text":"<pre><code>$ chmod +x run.sh\n$ ./run.sh\n</code></pre> <p>The daemon by default will serve at <code>127.0.0.1:5053</code>.</p>"}]}